{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----LOADING------\n",
      "-----SPLITTING------\n",
      "Split 1 documents into 105 chunks.\n",
      "-----CHROMA DB------\n",
      "-----CHAT BOT------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Professor Mohammad Q. Azhar is a computer information systems professor at CUNY BMCC and an expert in Educational Robotics, having led numerous workshops. He has also co-authored research on AI and mental health during the COVID-19 pandemic.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Importing document loaders and parsers\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain_community.document_loaders.generic import GenericLoader\n",
    "from langchain_community.document_loaders.parsers import LanguageParser\n",
    "\n",
    "# Importing text splitter\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_text_splitters import Language\n",
    "\n",
    "# Setting the directory path\n",
    "DIRECTORY_PATH = \"/Users/Chetan/PycharmProjects/RAG/Data\"\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------------\n",
    "# Loading documents from the specified directory\n",
    "print(\"-----LOADING------\")\n",
    "\n",
    "# Keyword arguments for text loader\n",
    "text_loader_kwargs = {'autodetect_encoding': True}\n",
    "\n",
    "# Create a DirectoryLoader instance\n",
    "directory_loader = DirectoryLoader(DIRECTORY_PATH, glob=\"./*.md\", loader_cls=TextLoader, loader_kwargs=text_loader_kwargs)\n",
    "\n",
    "# Load documents from the directory\n",
    "directory_documents = directory_loader.load()\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------------\n",
    "# Splitting loaded documents into smaller chunks\n",
    "print(\"-----SPLITTING------\")\n",
    "\n",
    "# Create a RecursiveCharacterTextSplitter instance\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=10,\n",
    "    length_function=len,\n",
    "    add_start_index=True,\n",
    ")\n",
    "\n",
    "# Split documents into chunks\n",
    "chunks = text_splitter.split_documents(directory_documents)\n",
    "print(f\"Split {len(directory_documents)} documents into {len(chunks)} chunks.\")\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------------\n",
    "# Creating a Chroma database from the chunks\n",
    "print(\"-----CHROMA DB------\")\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "\n",
    "# Create GPT4AllEmbeddings instance\n",
    "gpt4all_embd = GPT4AllEmbeddings()\n",
    "\n",
    "# Create Chroma database from chunks\n",
    "db = Chroma.from_documents(chunks, gpt4all_embd)\n",
    "\n",
    "# Create a retriever for the database\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\"k\": 8},\n",
    ")\n",
    "\n",
    "# Importing necessary modules for building retrieval chains and chat bot\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------------\n",
    "# Setting up a chat bot\n",
    "print(\"-----CHAT BOT------\")\n",
    "from langchain_community.chat_models.ollama import ChatOllama\n",
    "\n",
    "# Create ChatOllama instance\n",
    "llm = ChatOllama(model=\"mistral\")\n",
    "\n",
    "# Template for the system's response\n",
    "system_template = \"\"\"\n",
    "Answer the user's questions based on the below context.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
    "Use three sentences maximum and keep the answer as concise as possible:\n",
    "\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "# Creating a prompt for generating search queries\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_template),\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Creating a retrieval chain for answering user queries\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "qa_chain = create_retrieval_chain(retriever, document_chain)\n",
    "\n",
    "# Example queries\n",
    "qa_chain.pick(\"answer\").invoke({\"input\": \"who is the Professor?\"})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
