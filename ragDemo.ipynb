{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----LOADING------\n",
      "-----SPITING------\n",
      "Split 1 documents into 105 chunks.\n",
      "-----CHROMA DB------\n",
      "-----CHAT BOT------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Professor Azhar is a computer information systems professor at CUNY BMCC with a passion for robotics education. He has organized and taught numerous teacher training workshops for Educational Robotics, and is also a faculty advisor for computational thinking initiatives.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain_community.document_loaders.generic import GenericLoader\n",
    "from langchain_community.document_loaders.parsers import LanguageParser\n",
    "from langchain_text_splitters import Language\n",
    "\n",
    "DIRECTORY_PATH = \"/Users/Chetan/PycharmProjects/RAG/Data\"\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "print(\"-----LOADING------\")\n",
    "text_loader_kwargs={'autodetect_encoding': True}\n",
    "directoryLoader = DirectoryLoader(DIRECTORY_PATH, glob=\"./*.md\", loader_cls=TextLoader, loader_kwargs=text_loader_kwargs)\n",
    "directoryDocument = directoryLoader.load()\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "print(\"-----SPITING------\")\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=10,\n",
    "    length_function=len,\n",
    "    add_start_index=True,\n",
    ")\n",
    "chunks = text_splitter.split_documents(directoryDocument)\n",
    "print(f\"Split {len(directoryDocument)} documents into {len(chunks)} chunks.\")\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------------\n",
    "print(\"-----CHROMA DB------\")\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "\n",
    "gpt4all_embd = GPT4AllEmbeddings()\n",
    "\n",
    "db = Chroma.from_documents(chunks, gpt4all_embd)\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\"k\": 8},\n",
    ")\n",
    "\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "# -------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "print(\"-----CHAT BOT------\")\n",
    "from langchain_community.chat_models.ollama import ChatOllama\n",
    "llm = ChatOllama(model=\"mistral\")\n",
    "\n",
    "system_template = \"\"\"\n",
    "Answer the user's questions based on the below context.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
    "Use three sentences maximum and keep the answer as concise as possible:\n",
    "\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "# First we need a prompt that we can pass into an LLM to generate this search query\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_template),\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "qa_chain = create_retrieval_chain(retriever, document_chain)\n",
    "qa_chain.pick(\"answer\").invoke({\"input\": \"who is the Professor?\"})\n",
    "qa_chain.pick(\"answer\").invoke({\"input\": \"what you think about Professor Azhar?\"})\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
